{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data Loading and Preprocessing"
      ],
      "metadata": {
        "id": "8UHiij2AWXSD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtUA5zkFWTVK",
        "outputId": "ddf2909a-21e3-49d9-cd4b-5041d5b749cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation"
      ],
      "metadata": {
        "id": "lQOWBbYVWdqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "datagen.fit(x_train)\n"
      ],
      "metadata": {
        "id": "KrD_aEe_Wc23"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Architecture"
      ],
      "metadata": {
        "id": "sNMoOUoTWr5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "uKTRI2grWcim"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Model"
      ],
      "metadata": {
        "id": "rNRL1QHTWmuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZpM40ppXFbh",
        "outputId": "ec1255ed-e207-4503-9e7a-52aa9b588c83"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "781/781 [==============================] - 47s 46ms/step - loss: 1.7156 - accuracy: 0.4203 - val_loss: 1.4021 - val_accuracy: 0.5238\n",
            "Epoch 2/50\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 1.1743 - accuracy: 0.5815 - val_loss: 1.4795 - val_accuracy: 0.5626\n",
            "Epoch 3/50\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.9974 - accuracy: 0.6471 - val_loss: 1.0007 - val_accuracy: 0.6606\n",
            "Epoch 4/50\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.8986 - accuracy: 0.6840 - val_loss: 0.8323 - val_accuracy: 0.7196\n",
            "Epoch 5/50\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.8419 - accuracy: 0.7052 - val_loss: 1.0191 - val_accuracy: 0.6624\n",
            "Epoch 6/50\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.7833 - accuracy: 0.7277 - val_loss: 0.7349 - val_accuracy: 0.7459\n",
            "Epoch 7/50\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.7361 - accuracy: 0.7437 - val_loss: 0.7141 - val_accuracy: 0.7675\n",
            "Epoch 8/50\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.7093 - accuracy: 0.7544 - val_loss: 0.9588 - val_accuracy: 0.6973\n",
            "Epoch 9/50\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.6745 - accuracy: 0.7677 - val_loss: 0.6575 - val_accuracy: 0.7846\n",
            "Epoch 10/50\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.6446 - accuracy: 0.7766 - val_loss: 0.6526 - val_accuracy: 0.7817\n",
            "Epoch 11/50\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.6292 - accuracy: 0.7827 - val_loss: 0.6509 - val_accuracy: 0.7892\n",
            "Epoch 12/50\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.6065 - accuracy: 0.7894 - val_loss: 0.5702 - val_accuracy: 0.8107\n",
            "Epoch 13/50\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.5916 - accuracy: 0.7955 - val_loss: 0.5939 - val_accuracy: 0.8013\n",
            "Epoch 14/50\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.5697 - accuracy: 0.8030 - val_loss: 0.6137 - val_accuracy: 0.8001\n",
            "Epoch 15/50\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5555 - accuracy: 0.8093 - val_loss: 0.5709 - val_accuracy: 0.8044\n",
            "Epoch 16/50\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.5468 - accuracy: 0.8103 - val_loss: 0.5638 - val_accuracy: 0.8168\n",
            "Epoch 17/50\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.5354 - accuracy: 0.8154 - val_loss: 0.6333 - val_accuracy: 0.7905\n",
            "Epoch 18/50\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5209 - accuracy: 0.8201 - val_loss: 0.4784 - val_accuracy: 0.8397\n",
            "Epoch 19/50\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.5124 - accuracy: 0.8234 - val_loss: 0.4705 - val_accuracy: 0.8438\n",
            "Epoch 20/50\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.5052 - accuracy: 0.8245 - val_loss: 0.4801 - val_accuracy: 0.8403\n",
            "Epoch 21/50\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.4937 - accuracy: 0.8311 - val_loss: 0.4643 - val_accuracy: 0.8458\n",
            "Epoch 22/50\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.4866 - accuracy: 0.8322 - val_loss: 0.4963 - val_accuracy: 0.8359\n",
            "Epoch 23/50\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.4755 - accuracy: 0.8353 - val_loss: 0.5029 - val_accuracy: 0.8304\n",
            "Epoch 24/50\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.4731 - accuracy: 0.8355 - val_loss: 0.4226 - val_accuracy: 0.8615\n",
            "Epoch 25/50\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.4674 - accuracy: 0.8384 - val_loss: 0.4328 - val_accuracy: 0.8566\n",
            "Epoch 26/50\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.4595 - accuracy: 0.8417 - val_loss: 0.5131 - val_accuracy: 0.8286\n",
            "Epoch 27/50\n",
            "781/781 [==============================] - 32s 42ms/step - loss: 0.4525 - accuracy: 0.8424 - val_loss: 0.3947 - val_accuracy: 0.8712\n",
            "Epoch 28/50\n",
            "781/781 [==============================] - 32s 42ms/step - loss: 0.4438 - accuracy: 0.8474 - val_loss: 0.4185 - val_accuracy: 0.8602\n",
            "Epoch 29/50\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.4410 - accuracy: 0.8481 - val_loss: 0.4262 - val_accuracy: 0.8601\n",
            "Epoch 30/50\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.4328 - accuracy: 0.8505 - val_loss: 0.4620 - val_accuracy: 0.8472\n",
            "Epoch 31/50\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.4318 - accuracy: 0.8508 - val_loss: 0.4294 - val_accuracy: 0.8607\n",
            "Epoch 32/50\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.4267 - accuracy: 0.8544 - val_loss: 0.4180 - val_accuracy: 0.8632\n",
            "Epoch 33/50\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.4159 - accuracy: 0.8562 - val_loss: 0.4481 - val_accuracy: 0.8466\n",
            "Epoch 34/50\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.4210 - accuracy: 0.8557 - val_loss: 0.4475 - val_accuracy: 0.8528\n",
            "Epoch 35/50\n",
            "781/781 [==============================] - 32s 42ms/step - loss: 0.4083 - accuracy: 0.8580 - val_loss: 0.4270 - val_accuracy: 0.8617\n",
            "Epoch 36/50\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.4058 - accuracy: 0.8596 - val_loss: 0.4305 - val_accuracy: 0.8631\n",
            "Epoch 37/50\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.4055 - accuracy: 0.8596 - val_loss: 0.5048 - val_accuracy: 0.8396\n",
            "Epoch 38/50\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.4018 - accuracy: 0.8617 - val_loss: 0.4747 - val_accuracy: 0.8476\n",
            "Epoch 39/50\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.3959 - accuracy: 0.8618 - val_loss: 0.3732 - val_accuracy: 0.8739\n",
            "Epoch 40/50\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.3959 - accuracy: 0.8627 - val_loss: 0.3709 - val_accuracy: 0.8783\n",
            "Epoch 41/50\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.3874 - accuracy: 0.8662 - val_loss: 0.4549 - val_accuracy: 0.8525\n",
            "Epoch 42/50\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.3891 - accuracy: 0.8646 - val_loss: 0.3996 - val_accuracy: 0.8663\n",
            "Epoch 43/50\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.3865 - accuracy: 0.8659 - val_loss: 0.4814 - val_accuracy: 0.8443\n",
            "Epoch 44/50\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.3775 - accuracy: 0.8696 - val_loss: 0.4456 - val_accuracy: 0.8517\n",
            "Epoch 45/50\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.3758 - accuracy: 0.8683 - val_loss: 0.4680 - val_accuracy: 0.8499\n",
            "Epoch 46/50\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.3751 - accuracy: 0.8685 - val_loss: 0.3950 - val_accuracy: 0.8710\n",
            "Epoch 47/50\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.3727 - accuracy: 0.8707 - val_loss: 0.3462 - val_accuracy: 0.8801\n",
            "Epoch 48/50\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.3673 - accuracy: 0.8717 - val_loss: 0.4166 - val_accuracy: 0.8679\n",
            "Epoch 49/50\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.3675 - accuracy: 0.8713 - val_loss: 0.4274 - val_accuracy: 0.8618\n",
            "Epoch 50/50\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.3598 - accuracy: 0.8729 - val_loss: 0.3928 - val_accuracy: 0.8700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "mqGUCfqoXNHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAG4ydOpXL5X",
        "outputId": "4361a2da-6e8c-4d8b-ef43-bbcd1102c00b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3928 - accuracy: 0.8700\n",
            "Test Loss: 0.39283937215805054\n",
            "Test Accuracy: 0.8700000047683716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Loss: A test loss of 0.3928 indicates that the model is reasonably well-fitted to the test data. Loss values closer to zero are better, but this value suggests that the model is performing well, especially considering the complexity of the CIFAR-10 dataset.\n",
        "\n",
        "Test Accuracy: An accuracy of 87.00% is a significant improvement. It indicates that the model correctly classifies 87 out of 100 images. This is a good result for CIFAR-10, where achieving very high accuracy is challenging due to the dataset's diversity and complexity.\n",
        "\n",
        "Data Augmentation: Using data augmentation has likely contributed to the improved performance by making the model more robust to variations in the input data.\n",
        "\n",
        "Overall, achieving 87% accuracy on CIFAR-10 is a strong result. The revised model architecture and data augmentation strategies have significantly improved the model's performance. Continue experimenting with the mentioned techniques to push the model's accuracy even higher."
      ],
      "metadata": {
        "id": "dW7xTfpEXKzE"
      }
    }
  ]
}